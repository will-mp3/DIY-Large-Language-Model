{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# important to node cuda is not M1 compatible, instead we use mps\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00133705\n",
      "CPU times: user 1.13 ms, sys: 1.51 ms, total: 2.64 ms\n",
      "Wall time: 1.56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "start_time = time.time()\n",
    "# matrix operations here\n",
    "zeros = torch.zeros(1, 1)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "# number following the colon denotes # of decimal places our result will show\n",
    "print(f\"{elapsed_time:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01102209\n",
      "0.24082708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vl/18qq_7f10sg58pq4sv0f37m40000gn/T/ipykernel_45818/740059484.py:19: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  rand = np.multiply(np_rand1, np_rand2)\n"
     ]
    }
   ],
   "source": [
    "torch_rand1 = torch.rand(100, 100, 100, 100).to(device)\n",
    "torch_rand2 = torch.rand(100, 100, 100, 100).to(device)\n",
    "np_rand1 = torch.rand(100, 100, 100, 100)\n",
    "np_rand2 = torch.rand(100, 100, 100, 100)\n",
    "\n",
    "# torch using GPU\n",
    "start_time = time.time()\n",
    "\n",
    "rand = (torch_rand1 @ torch_rand2) # use @ to multiply matrices in pytorch\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.8f}\")\n",
    "\n",
    "# numpy using CPU\n",
    "start_time = time.time()\n",
    "\n",
    "rand = np.multiply(np_rand1, np_rand2)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.stack, torch.multinomial, torch.tril, torch.triu, input.T / input.transpose, nn.linear, torch.cat, F.softmax\n",
    "# show all the examples of functions/methods with pytorch docs\n",
    "\n",
    "# define a probability tensor\n",
    "probabilities = torch.tensor([0.1, 0.9])\n",
    "# 10% 0r 0.1 => 0, 90%or 0.9 => 1. each probability points to the index of the probability in the tensor\n",
    "# draw 5 examples from the multinomial distribution\n",
    "samples = torch.multinomial(probabilities, num_samples=10, replacement=True)\n",
    "samples\n",
    "\n",
    "# we will use this for text probability and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3, 4])\n",
    "out = torch.cat((tensor, torch.tensor([5])), dim=0)\n",
    "out\n",
    "\n",
    "# we will use this when we are generating text given a context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tril ~ triangle lower\n",
    "out = torch.tril(torch.ones(5, 5))\n",
    "out\n",
    "\n",
    "# we will use this to represent history/context (1s) and future predictions (0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 0., 1., 1., 1.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# triu ~ triangle upper\n",
    "out = torch.triu(torch.ones(5, 5))\n",
    "out\n",
    "\n",
    "# same concept as above but reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf, -inf],\n",
       "        [0., 0., 0., -inf, -inf],\n",
       "        [0., 0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.zeros(5, 5).masked_fill(torch.tril(torch.ones(5, 5)) == 0, float('-inf'))\n",
    "out\n",
    "\n",
    "# exponentiating these elements will get us to the point above, 0 becomes 1 and -inf becomes 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.exp(out)\n",
    "\n",
    "# as described in the above cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 2])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.zeros(2, 3, 4)\n",
    "out = input.transpose(0, 2)\n",
    "out.shape\n",
    "\n",
    "# this swaps the elements of the 0th index and the 2nd index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1 = torch.tensor([1, 2, 3])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "tensor3 = torch.tensor([7, 8, 9])\n",
    "\n",
    "# stack the tensors along a new dimension\n",
    "stacked_tensor = torch.stack([tensor1, tensor2, tensor3])\n",
    "stacked_tensor\n",
    "\n",
    "# we will use this with our blocks to make batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6283, -3.3214, -1.7670], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "sample = torch.tensor([10., 10., 10.])\n",
    "linear = nn.Linear(3, 3, bias=False) # linear transformation\n",
    "print(linear(sample))\n",
    "\n",
    "# we will use these for training and parameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0900, 0.2447, 0.6652])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# create a tensor\n",
    "tensor1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "\n",
    "# apply softmax using torch.nn.function.softmax()\n",
    "softmax_output = F.softmax(tensor1, dim=0)\n",
    "\n",
    "print(softmax_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 100])\n"
     ]
    }
   ],
   "source": [
    "# initialize an embedding layer\n",
    "vocab_size = 1000\n",
    "embedding_dim = 100\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "# create some input indices\n",
    "input_indices = torch.LongTensor([1, 5, 3, 2])\n",
    "\n",
    "# apply the embedding layer\n",
    "embedded_output = embedding(input_indices)\n",
    "\n",
    "# the output will be a tensor of shape (4, 100), where 4 is the number of inputs\n",
    "# and 100 is the dimensionality of the embedding vectors\n",
    "print(embedded_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n",
      "tensor([[ 27,  30,  33],\n",
      "        [ 61,  68,  75],\n",
      "        [ 95, 106, 117]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4], [5, 6]])\n",
    "b = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "print(a @ b)\n",
    "print(torch.matmul(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[0.5060, 0.2227, 0.6172],\n",
      "        [0.8846, 0.8201, 0.8661]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# type int64\n",
    "int64 = torch.randint(1, (3, 2)).float()\n",
    "print(int64)\n",
    "\n",
    "# type float32\n",
    "float32 = torch.rand(2, 3)\n",
    "print(float32)\n",
    "\n",
    "result = torch.matmul(int64, float32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 3, 5)\n",
    "x, y, z = a.shape\n",
    "a = a.view(x, y, z)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7619, 0.5314, 0.3582, 0.0539, 0.8084, 0.6856, 0.3212, 0.9076, 0.5600,\n",
      "         0.2982],\n",
      "        [0.2797, 0.8773, 0.8572, 0.0230, 0.0947, 0.3313, 0.8494, 0.4594, 0.6813,\n",
      "         0.4347],\n",
      "        [0.5512, 0.3078, 0.7862, 0.2602, 0.4782, 0.0165, 0.5352, 0.8503, 0.9971,\n",
      "         0.5553],\n",
      "        [0.0164, 0.8575, 0.8180, 0.9545, 0.8254, 0.0084, 0.0653, 0.3390, 0.7389,\n",
      "         0.3482],\n",
      "        [0.5612, 0.8002, 0.5717, 0.8086, 0.3394, 0.3796, 0.2710, 0.6163, 0.8348,\n",
      "         0.6676],\n",
      "        [0.4080, 0.0220, 0.5716, 0.4639, 0.1927, 0.8059, 0.8064, 0.0735, 0.8600,\n",
      "         0.3534],\n",
      "        [0.2942, 0.6435, 0.3932, 0.2838, 0.8932, 0.4533, 0.2948, 0.1759, 0.5860,\n",
      "         0.7337],\n",
      "        [0.4874, 0.4482, 0.6619, 0.4689, 0.7296, 0.9578, 0.9322, 0.9309, 0.1110,\n",
      "         0.4954],\n",
      "        [0.9930, 0.8780, 0.0415, 0.0237, 0.7410, 0.1854, 0.5681, 0.4599, 0.8085,\n",
      "         0.9338],\n",
      "        [0.1778, 0.8424, 0.7371, 0.6263, 0.4157, 0.9547, 0.6770, 0.1393, 0.7189,\n",
      "         0.8767],\n",
      "        [0.7951, 0.5972, 0.7161, 0.5940, 0.4328, 0.3068, 0.7990, 0.6820, 0.8435,\n",
      "         0.2241],\n",
      "        [0.5971, 0.4968, 0.2007, 0.4371, 0.7882, 0.0074, 0.6777, 0.4332, 0.1398,\n",
      "         0.5012],\n",
      "        [0.3770, 0.2346, 0.4814, 0.7485, 0.1972, 0.8402, 0.4207, 0.0266, 0.0816,\n",
      "         0.2333],\n",
      "        [0.0678, 0.5468, 0.9617, 0.8926, 0.3899, 0.7449, 0.9439, 0.0640, 0.1754,\n",
      "         0.0686],\n",
      "        [0.8258, 0.7356, 0.4838, 0.0603, 0.2061, 0.0114, 0.3804, 0.7044, 0.0151,\n",
      "         0.5694],\n",
      "        [0.9334, 0.5275, 0.5518, 0.6489, 0.7112, 0.4496, 0.2251, 0.6949, 0.9617,\n",
      "         0.0870],\n",
      "        [0.3560, 0.2861, 0.1355, 0.8887, 0.8392, 0.8815, 0.2789, 0.7206, 0.8105,\n",
      "         0.6537],\n",
      "        [0.6603, 0.2150, 0.3029, 0.2908, 0.9773, 0.6493, 0.9750, 0.8434, 0.1419,\n",
      "         0.1133],\n",
      "        [0.2294, 0.4221, 0.2431, 0.0724, 0.1861, 0.2465, 0.0283, 0.8533, 0.6958,\n",
      "         0.2947],\n",
      "        [0.1708, 0.2364, 0.9846, 0.5363, 0.7446, 0.5324, 0.0164, 0.5703, 0.9713,\n",
      "         0.3889],\n",
      "        [0.8159, 0.7553, 0.6167, 0.9496, 0.7933, 0.7582, 0.3627, 0.5399, 0.6728,\n",
      "         0.9273],\n",
      "        [0.0270, 0.3341, 0.3549, 0.2351, 0.0072, 0.3601, 0.7031, 0.0982, 0.2723,\n",
      "         0.2587],\n",
      "        [0.9389, 0.1033, 0.8675, 0.7702, 0.7738, 0.5435, 0.4919, 0.3317, 0.0272,\n",
      "         0.5107],\n",
      "        [0.5290, 0.4588, 0.6572, 0.6365, 0.4494, 0.6056, 0.5932, 0.5240, 0.2284,\n",
      "         0.2409],\n",
      "        [0.0900, 0.2894, 0.8402, 0.3308, 0.4726, 0.4407, 0.8208, 0.0766, 0.8662,\n",
      "         0.3488],\n",
      "        [0.0538, 0.2595, 0.9447, 0.6746, 0.1245, 0.1574, 0.1704, 0.1228, 0.4114,\n",
      "         0.4929],\n",
      "        [0.7950, 0.0901, 0.3927, 0.2099, 0.5643, 0.7958, 0.2154, 0.1791, 0.3879,\n",
      "         0.5292],\n",
      "        [0.8686, 0.0656, 0.9027, 0.5462, 0.6853, 0.0517, 0.0706, 0.0062, 0.7059,\n",
      "         0.4179],\n",
      "        [0.5510, 0.2366, 0.8088, 0.9775, 0.9518, 0.5174, 0.5105, 0.1488, 0.7071,\n",
      "         0.8607],\n",
      "        [0.7331, 0.9770, 0.1466, 0.4651, 0.1013, 0.2084, 0.1480, 0.6592, 0.4827,\n",
      "         0.3516],\n",
      "        [0.4076, 0.9637, 0.2435, 0.8448, 0.2058, 0.8522, 0.7959, 0.7988, 0.7389,\n",
      "         0.1235],\n",
      "        [0.2753, 0.6636, 0.6046, 0.0629, 0.8242, 0.1285, 0.8971, 0.9977, 0.7935,\n",
      "         0.4269]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.rand((4, 8, 10))\n",
    "B, T, C = input.shape\n",
    "output = input.view(B*T, C)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu kernel",
   "language": "python",
   "name": "gpu_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
